# Study Task Insights ‚Äî Backend + Infraestructura üß†

## üöÄ Introducci√≥n

**Study Task Insights** es una API desarrollada con **Node.js (Express)**, **Prisma ORM** y **PostgreSQL**, dise√±ada para analizar h√°bitos de estudio y productividad acad√©mica.
Incluye integraci√≥n con un **LLM local (Ollama + Qwen2.5-7B-Instruct)** que genera recomendaciones semanales inteligentes a partir de los datos del usuario.

La API est√° **contenedorizada con Docker** y documentada en **Postman**:

- [Postman ‚Äì Study Task Insights API](https://www.postman.com/devprojects-team/study-task-insights/collection/o74ljke/study-task-insights-api)

## ‚öôÔ∏è Requisitos previos

Antes de iniciar el backend, aseg√∫rate de tener instalado:

| Componente    | Versi√≥n m√≠nima recomendada | Descripci√≥n                                       |
| ------------- | -------------------------- | ------------------------------------------------- |
| üß© Node.js    | `22.x`                     | Entorno de ejecuci√≥n.                             |
| üì¶ pnpm       | `>=9.x`                    | Gestor de dependencias r√°pido y reproducible.     |
| üê≥ Docker     | `>=24.x`                   | Para orquestar los contenedores de API, DB y LLM. |
| üêò PostgreSQL | `16`                       | Base de datos relacional usada por Prisma.        |

> **Nota:** En caso de usar docker unicamente tener instalado docker y docker-compose.

### Asegurar tener entorno preparado

```bash
node -v
pnpm -v
docker -v
```

## üìÅ Estructura general del proyecto

```bash
study-task-insights/
‚îú‚îÄ‚îÄ server/                  # Backend (Express + Prisma + LLM)
‚îÇ   ‚îú‚îÄ‚îÄ src/                 # C√≥digo fuente principal
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml   # Orquestaci√≥n de contenedores
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile           # Imagen base Node.js 22
‚îÇ   ‚îî‚îÄ‚îÄ migrations/          # Scripts SQL de inicializaci√≥n
‚îî‚îÄ‚îÄ docs/server              # Documentaci√≥n t√©cnica "backend"
```

## üß© Backend (API)

El backend est√° compuesto por tres servicios dentro de `server/docker-compose.yml`:

| Servicio   | Rol                             | Estado de red |
| ---------- | ------------------------------- | ------------- |
| **db**     | PostgreSQL 16 (persistencia)    | Red interna   |
| **api**    | Express + Prisma + l√≥gica LLM   | Puerto xxxx   |
| **ollama** | Motor LLM (Qwen2.5-7B-Instruct) | Red interna   |

El contenedor `ollama-init` descarga el modelo de forma autom√°tica al inicio.
Una vez completado, la API puede comunicarse con el modelo v√≠a `http://ollama:11434`.

## üß± Configuraci√≥n de entorno

Copia el archivo de entorno base:

```bash
cd server
cp .env.example .env
```

Edita los valores en `.env` seg√∫n tu entorno local o productivo, revisa la documentaci√≥n sobre [variables de entorno](https://github.com/JosueSay/study-task-insights/blob/main/docs/code/server/env.md) para configurarlo.

## üê≥ Ejecuci√≥n del entorno Docker

Todos los comandos deben ejecutarse desde la carpeta `server/`. Este flujo permite levantar el entorno completo (PostgreSQL + API + LLM).

### Ciclo de ejecuci√≥n completo

```bash
# 1Ô∏è‚É£ Detener y eliminar todos los contenedores y vol√∫menes persistentes
docker compose down -v

# 2Ô∏è‚É£ Construir y levantar los contenedores
docker compose up -d

# 3Ô∏è‚É£ Descargar y verificar el modelo de Ollama (solo la primera vez)
docker compose exec ollama ollama pull qwen2.5:7b-instruct
docker compose exec ollama ollama list

# 4Ô∏è‚É£ Verificar logs de inicializaci√≥n y estado
docker compose logs -f db
docker compose logs -f ollama-init
docker compose logs -f ollama
docker compose logs -f api
```

### Administraci√≥n de contenedores

```bash
# Reiniciar un contenedor espec√≠fico
docker compose restart api
docker compose restart ollama

# Eliminar contenedores espec√≠ficos (manteniendo la red y los vol√∫menes)
docker compose rm -f ollama ollama-init api
```

### Operaciones dentro de los contenedores

```bash
# Ingresar al shell del contenedor de la API
docker compose exec api sh

# Listar modelos disponibles en Ollama
docker compose exec ollama ollama list

# Descargar manualmente un modelo (si fuera necesario)
docker compose exec ollama ollama pull qwen2.5:7b-instruct
```

### Finalizar ejecuci√≥n

```bash
# Detener contenedor
docker compose stop

# Volver a encenderlos
docker compose start
```
